---
title: "Project Two"
output:
  pdf_document: default
  html_document: default
---

Due Oct. 25 at 11:59 PM. 

For this first part of the exam, you can either use `surveys_complete.csv` or your own data. If you are using your own data, you must have data in which you think you have a numerical predictor variable and a numerical response variable. If you are using `surveys_complete`, you can use weight and hindfoot_length for this.

Save this file in your `projects` directory. You can either save it in a project two subdirectory, or just put it in projects. Either way is fine.


1) Load in your data. Which variable will you be using as a predictor, and which as a response? (5 pts)

```{r}
#Fish_Data <- read.csv("Fish_Data.csv")

#Predictor = SL(Standard length)
#Response = LL(Lateral line length)


```

```
# Answer which column is predictor and which is response
```

2) Plot the two against each other with a scatter plot. Do the data appear to be related linearly? (5 pts)


```{r}
#lm_model_one <- lm(SL ~ LL, data = Fish_Data)
ggplot(Fish_Data, aes(x = SL, y = LL)) + 
    geom_point(size = 0.5) +        
    labs(x = "Standard Length", 
         y = "Lateral Line Length")
   
  

```

```
#Based on the scatterplot they do not look linearly related. 

```


3) Fit the linear model. View the summary. (5 pts)


```{r}



lm_model_one <- lm(SL ~ LL, data = Fish_Data)
summary(lm_model_one)
ggplot(Fish_Data, aes(x = SL, y = LL)) + 
    geom_point(size = 0.5) +        
    geom_smooth(method = "lm",     
                color = "navy",    
                size = 0.5,        
                fill = "orange4") + 
    labs(x = "Standard Length", 
         y = "Lateral Line Length") + 
    annotate("text",                
             x = 35, y = 45,         
             label = "R^2 == 0.0233 ", 
             parse=T) +
    theme_bw()

#Calculated R^2 value: broom::glance(lm_model_one)
 
#AMW: That is a pretty classic "no relationship" 

```

4) Does the summary make sense when you compare it to the plot you made? Does our model have good predictive power? Evaluate the residual standard error, intercept, and R-Squared in particular. Would you say your predictor predicts the response?  (10 pts)


```
# Yes, I would say the summary backs up the weak relationship shown in my plot. No, I would say the model has poor predictive power. Since the R^2 value is so low(0.0233) this tells us that lateral line length  is not a strong predictor of standard length. Also the high intercept and RSE values further back this up. 
```


5) Plot the model on the graph. Increase the size of the text so it is comfortably readable at 5 feet. Make sure axis labels are readable and not overlapping with one another. (5 pts)

```{r}
#  summary(lm_model_one)

lm_model_one <- lm(SL ~ LL, data = Fish_Data)
ggplot(Fish_Data, aes(x = SL, y = LL)) + 
    geom_point(size = 0.5) +        
    geom_smooth(method = "lm",     
                color = "navy",    
                size = 0.5,        
                fill = "orange4") + 
    labs(x = "Standard Length", 
         y = "Lateral Line Length") + 
    annotate("text",                
             x = 35, y = 45,         
             label = "R^2 == 0.0233 ", 
             parse=T) +
    theme_bw() +
    theme(text=element_text(size = 12))

```


6) Check the normality of the residuals. Do they look OK? Are we violating assumptions? (5 pts)

```{r}

augmented_fit <- broom::augment(lm_model_one)
qqnorm(augmented_fit$.resid)
qqline(augmented_fit$.resid, col="red")
shapiro.test(augmented_fit$.resid)

#Based on how the graph looks it is safe to say that the data is not really normally distributed as a majority of points fail to fall on the trend line and are overall all over the place. However by doing a shapiro wilks it reveals a high p value is meaning you cant reject the idea that's normal.  

```

Why is normality of residuals important? 

```{r}

#Understanding if your data is/not normally distributed is important because it helps interpret the accuracy of the data. Factors such as the p value and confidence intervals are critical of assessing the hypothesis you want to test. 
#AMW: But why? The data themselves aren't accurate or inaccurate - they're the data. In the case of a non-normal model, some part of your data is being modeled better than some other part.
```

7) If you are using `surveys_complete`: Is there interspecific variation in the linear model? Hint: look at our prior work with facet plots. (15 pts) 

If you are *not* using  `surveys_complete`: Do you think there are groupings within your data that may have a separate linear model? Try grouping the data by that variable and redoing the lm. If this would not make sense for your data, you may also attempt to do multiple predictor variables. (15 pts)

```{r}
# No I don't think its possible based on the data given. Taking a look into the data  you can see that there are not really any good linear groupings. However, here is an example based on the two other numerical factors that are in my given data set. Again the low R^2 value given from this tells me that this data is not linearly related. This is really highlighted when we compare the new and old plot. 

lm_model_four <- lm(LL ~ CPD  , data = Fish_Data)
ggplot(Fish_Data, aes(x = LL, y = CPD,)) + 
    geom_point(size = 0.5) +        
    geom_smooth(method = "lm",     
                color = "navy",    
                size = 0.5,        
                fill = "purple4") + 
    labs(x = "Lateral Line Length", 
         y = "Caudal Peduncle Depth") + 
    annotate("text",                
             x = 75, y = 35,         
             label = "R^2 == 0.0397  ", 
             parse=T) +
    theme_bw()


#Calculated R^2 value: broom::glance(lm_model_four)

lm_model_one <- lm(SL ~ LL, data = Fish_Data)
summary(lm_model_one)
ggplot(Fish_Data, aes(x = SL, y = LL)) + 
    geom_point(size = 0.5) +        
    geom_smooth(method = "lm",     
                color = "navy",    
                size = 0.5,        
                fill = "orange4") + 
    labs(x = "Standard Length", 
         y = "Lateral Line Length") + 
    annotate("text",                
             x = 35, y = 45,         
             label = "R^2 == 0.0233 ", 
             parse=T) +
    theme_bw()


view(Fish_Data)




```

## Part Two

In this portion, you are free to use your own data if you have a categorical predictor variable and a response variable. Otherwise, you may use the columns sex and weight in `surveys_complete`

1) First, plot the data grouped by sex (5 pts)

```{r}

Fish_Data %>% 
 filter(Sex != "j") %>%
 group_by(SL, Sex) %>%
 ggplot(Fish_Data, mapping = aes(x = Sex, y = SL, color = Sex)) +
    geom_jitter() +  xlab("Sex") + ylab("Standard Length") + 
    stat_summary(fun.data = "mean_se", color = "black") 

```

2) Try an ANOVA of this data (5 pt)

```{r}
lm_model_two <- lm(SL ~ Sex, data = Fish_Data)
anova_model <- aov(lm_model_two)
summary(anova_model)


```

3) How about a linear model? What information does this give you that an ANOVA can't? (5 pts)


```{r}
lm_model_two <- lm(SL ~ Sex, data = Fish_Data) 
summary(lm_model_two)


```

```
#A linear model provides more insight into the relationship and fit between the variables by showing you the R^2 value and coefficients like the slope values. This helps show how the predictor affects the response.

```

3) Plot the lm with the data, with points colored by sex. (10 pts)


```{r}
#lm(SL ~ Sex, data = Fish_Data)
 ggplot(Fish_Data, aes(x = Sex, y = SL, color = Sex)) + 
     geom_point() +
     xlab("Sex") + ylab("Standard Length") + 
     geom_smooth(method = "lm")
```

4) Choose any model we've looked at so far, but use two predictor variables. Perform an LM, plot the results, and state if this changes your interpretation of the relationship between variables (10 pts)

```{r}
 
lm_model_three <- lm(SL ~ County + LL, data = Fish_Data)
summary(lm_model_three)

#This model doesn't really improve my interpretation of the data due to the lack of statistical significance and variance between the two variables. 
```

```{r}
ggplot(Fish_Data, aes(x = LL, y = SL, color = County)) + 
    geom_point() +
    geom_smooth(method = "lm", aes(group = County)) +
    xlab("Lateral Line Length") + ylab("Standard Length") + 
  facet_wrap( "County")
#AMW: That's more interesting. 
```

```
# Text answer here
```

## Part Three


1) Add and commit this document (5 pts)

```
#Commands here
```

2) Push your changes to github (10 pts)

```
#Commands here
```



# MS students

My expectation is that you'll do this with your own data. If any part of this doesn't make sense with your data, please get in touch ASAP so we can work it out.
